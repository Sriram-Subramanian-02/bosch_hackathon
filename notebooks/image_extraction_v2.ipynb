{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Extraction\n",
    "\n",
    "When a query related to images are asked, the relavent image_ids are extracted from the image chunks stored in QDrant DB, which are given to Cohere LLM and prompted to extract the suitable image, given the image summary and the user query. If the retrieved image meets the threshold, it will be displayed to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.llms import Cohere\n",
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client.http import models\n",
    "from qdrant_client import QdrantClient, models\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain.load import dumps, loads\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, SentenceTransformerEmbeddings\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from sentence_transformers.util import cos_sim\n",
    "import PyPDF2\n",
    "from langchain.embeddings.cohere import CohereEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from operator import itemgetter\n",
    "from langchain.load import dumps, loads\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings.cohere import CohereEmbeddings\n",
    "from langchain.llms import Cohere\n",
    "import numpy as np\n",
    "from sentence_transformers.util import cos_sim\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.document_loaders import TextLoader\n",
    "import qdrant_client\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "import pandas as pd\n",
    "from qdrant_client import models, QdrantClient\n",
    "import cohere\n",
    "import numpy as np\n",
    "from qdrant_client.http.models import Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "QDRANT_URL = \"https://35ebdc7d-ec99-4ebd-896c-ff5705cf369b.us-east4-0.gcp.cloud.qdrant.io:6333\"\n",
    "QDRANT_API_KEY = \"9dKJsKOYwT0vGlWPrZXBSIlbUzvRdJ1XkM0_floo8FmYCOHX_Y0y-Q\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COHERE_API_KEY = \"V5jqL0gNm1xo9gIzN0x32c9Nc814b4gh9gpOY6EY\"\n",
    "\n",
    "os.environ[\"COHERE_API_KEY\"] = COHERE_API_KEY\n",
    "TOP_K = 10\n",
    "MAX_DOCS_FOR_CONTEXT = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import base64\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pymupdf\n",
    "import fitz\n",
    "\n",
    "def encode_image(image_path):\n",
    "    ''' Getting the base64 string '''\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def plt_img_base64(img_base64):\n",
    "\n",
    "    # Create an HTML img tag with the base64 string as the source\n",
    "    image_html = f'<img src=\"data:image/jpeg;base64,{img_base64}\" />'\n",
    "\n",
    "    # Display the image by rendering the HTML\n",
    "    display(HTML(image_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "MONGO_DB_URL = \"mongodb+srv://sriram:Ayynar%40123@msd.ywfrjgy.mongodb.net/?retryWrites=true&w=majority\"\n",
    "\n",
    "\n",
    "def get_collection(db_name = \"bosch\", collection_name = \"images_v1\"):\n",
    "    client = MongoClient(MONGO_DB_URL)\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "\n",
    "    return collection\n",
    "\n",
    "\n",
    "def store_in_mongodb(encoded_val, file_name):\n",
    "    # Get the collection\n",
    "    collection = get_collection()\n",
    "\n",
    "    # Check if the document with the same file_name already exists\n",
    "    existing_document = collection.find_one({\"file_name\": file_name})\n",
    "\n",
    "    if existing_document:\n",
    "        # Document with the same file_name already exists, delete it\n",
    "        collection.delete_one({\"file_name\": file_name})\n",
    "        print(f\"Existing document with file_name {file_name} deleted.\")\n",
    "\n",
    "    # Define the document to be inserted\n",
    "    document = {\n",
    "        \"encoded_val\": encoded_val,\n",
    "        \"file_name\": file_name\n",
    "    }\n",
    "\n",
    "    # Insert the document into the collection\n",
    "    result = collection.insert_one(document)\n",
    "\n",
    "    # Return the inserted document's ID\n",
    "    return result.inserted_id\n",
    "\n",
    "\n",
    "def get_file_details(file_name):\n",
    "    # Get the collection\n",
    "    collection = get_collection()\n",
    "\n",
    "    # Query the collection for the document with the specified file_name\n",
    "    document = collection.find_one({\"file_name\": file_name}, {\"_id\": 0, \"file_name\": 1, \"encoded_val\": 1})\n",
    "\n",
    "    # Check if the document was found and return the relevant details\n",
    "    if document:\n",
    "        return document\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def delete_all_data_from_collection(db_name=\"bosch\", collection_name=\"images_v1\"):\n",
    "    # Get the collection\n",
    "    collection = get_collection(db_name, collection_name)\n",
    "    \n",
    "    # Delete all documents in the collection\n",
    "    result = collection.delete_many({})\n",
    "    \n",
    "    # Return the count of deleted documents\n",
    "    return result.deleted_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "COHERE_API_KEY = \"8Coue2HcZqaJ1pAvM8NJ6XbriT76IfhsPEnq2OGE\"\n",
    "QDRANT_URL = \"https://35ebdc7d-ec99-4ebd-896c-ff5705cf369b.us-east4-0.gcp.cloud.qdrant.io:6333\"\n",
    "QDRANT_API_KEY = \"9dKJsKOYwT0vGlWPrZXBSIlbUzvRdJ1XkM0_floo8FmYCOHX_Y0y-Q\"\n",
    "QDRANT_COLLECTION_NAME = \"owners_manual_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\"Rerank docs (Reciprocal Rank Fusion)\n",
    "\n",
    "    Args:\n",
    "        results (list[list]): retrieved documents\n",
    "        k (int, optional): parameter k for RRF. Defaults to 60.\n",
    "\n",
    "    Returns:\n",
    "        ranked_results: list of documents reranked by RRF\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n\\n\\nresults in rrf function: \", len(results))\n",
    "\n",
    "    fused_scores = {}\n",
    "    for docs in results:\n",
    "        # Assumes the docs are returned in sorted order of relevance\n",
    "        for rank, doc in enumerate(docs):\n",
    "            print(doc)\n",
    "            doc_str = dumps(doc)\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # return only documents\n",
    "    return [x[0] for x in reranked_results[:MAX_DOCS_FOR_CONTEXT]]\n",
    "\n",
    "\n",
    "def query_generator(original_query: dict) -> list[str]:\n",
    "    \"\"\"Generate queries from original query\n",
    "\n",
    "    Args:\n",
    "        query (dict): original query\n",
    "\n",
    "    Returns:\n",
    "        list[str]: list of generated queries\n",
    "    \"\"\"\n",
    "\n",
    "    # original query\n",
    "    query = original_query.get(\"query\")\n",
    "\n",
    "    # prompt for query generator\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful assistant that generates multiple search queries based on a single input query.\"),\n",
    "        (\"user\", \"Generate multiple search queries related to:  {original_query}. When creating queries, please refine or add closely related contextual information, without significantly altering the original query's meaning\"),\n",
    "        (\"user\", \"OUTPUT (3 queries):\")\n",
    "    ])\n",
    "\n",
    "    # LLM model\n",
    "    model = Cohere()\n",
    "\n",
    "    # query generator chain\n",
    "    query_generator_chain = (\n",
    "        prompt | model | StrOutputParser() | (lambda x: x.split(\"\\n\"))\n",
    "    )\n",
    "\n",
    "    # gererate queries\n",
    "    queries = query_generator_chain.invoke({\"original_query\": query})\n",
    "\n",
    "    # add original query\n",
    "    queries.insert(0, \"0. \" + query)\n",
    "\n",
    "    print(queries)\n",
    "\n",
    "    return queries\n",
    "\n",
    "\n",
    "def rrf_retriever(query: str) -> list[Document]:\n",
    "    \"\"\"RRF retriever\n",
    "\n",
    "    Args:\n",
    "        query (str): Query string\n",
    "\n",
    "    Returns:\n",
    "        list[Document]: retrieved documents\n",
    "    \"\"\"\n",
    "\n",
    "    # Retriever\n",
    "    embedding = CohereEmbeddings(model = \"embed-english-v3.0\")\n",
    "    \n",
    "    qdrant_client = QdrantClient(\n",
    "        QDRANT_URL,\n",
    "        prefer_grpc=True,\n",
    "        api_key=QDRANT_API_KEY,\n",
    "    )\n",
    "    print(qdrant_client)\n",
    "\n",
    "    qdrant = Qdrant(\n",
    "        client=qdrant_client,\n",
    "        collection_name=QDRANT_COLLECTION_NAME,\n",
    "        embeddings=embedding,\n",
    "    )\n",
    "\n",
    "    retriever = qdrant.as_retriever(\n",
    "        search_kwargs={'k': TOP_K},\n",
    "        metadata={}\n",
    "    )\n",
    "\n",
    "    # RRF chain\n",
    "    chain = (\n",
    "        {\"query\": itemgetter(\"query\")}\n",
    "        | RunnableLambda(query_generator)\n",
    "        | retriever.map()\n",
    "        | reciprocal_rank_fusion\n",
    "    )\n",
    "\n",
    "    # invoke\n",
    "    result = chain.invoke({\"query\": query})\n",
    "    print(result)\n",
    "\n",
    "    image_ids = []\n",
    "    from itertools import chain\n",
    "    for document in result:\n",
    "        image_ids.append(document.metadata['image_ids'])\n",
    "    image_ids = list(chain.from_iterable([item] if isinstance(item, str) else item for item in image_ids if item is not None))\n",
    "\n",
    "    print(image_ids)\n",
    "\n",
    "    return result, image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_probing_conditions(context_list, query_emb, threshold):\n",
    "    co = cohere.Client(api_key=COHERE_API_KEY)\n",
    "    model=\"embed-english-v3.0\"\n",
    "    input_type=\"search_query\"\n",
    "\n",
    "    time.sleep(1)\n",
    "    res = co.embed(texts=context_list,\n",
    "                    model=model,\n",
    "                    input_type=input_type)\n",
    "\n",
    "    counter = 0\n",
    "    for i in res.embeddings:\n",
    "        if float(cos_sim(query_emb.embeddings, i)[0][0]) < threshold:\n",
    "            print(float(cos_sim(query_emb.embeddings, i)[0][0]))\n",
    "            counter += 1\n",
    "\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_images_context(image_ids):\n",
    "    text_to_image_ids = dict()\n",
    "\n",
    "    qdrant_client = QdrantClient(\n",
    "        QDRANT_URL,\n",
    "        prefer_grpc=True,\n",
    "        api_key=QDRANT_API_KEY,\n",
    "    )\n",
    "\n",
    "    should_filters = list()\n",
    "\n",
    "    for i in image_ids:\n",
    "        should_filters.append(\n",
    "            models.FieldCondition(\n",
    "                    key=\"metadata.image_ids\",\n",
    "                    match=models.MatchValue(value=i),\n",
    "                )\n",
    "        )\n",
    "\n",
    "    must_filters=[models.FieldCondition(key=\"metadata.chunk_type\", match=models.MatchValue(value=\"Image\"))]\n",
    "\n",
    "    for i in qdrant_client.scroll(collection_name=f\"{QDRANT_COLLECTION_NAME}\", scroll_filter=models.Filter(should=should_filters, must=must_filters),limit=100)[0]:\n",
    "        text_to_image_ids[i.payload['page_content']] = i.payload['metadata']['image_ids']\n",
    "\n",
    "    return text_to_image_ids\n",
    "\n",
    "from langchain_together.embeddings import TogetherEmbeddings\n",
    "\n",
    "def get_similarity_together(documents):\n",
    "    os.environ[\"TOGETHER_API_KEY\"] = \"148521c4088ad416dced465cc144671626b00c860af4e6ebc855953567087d8a\"\n",
    "    embeddings = TogetherEmbeddings(model=\"togethercomputer/m2-bert-80M-8k-retrieval\")\n",
    "    embeds = embeddings.embed_documents(documents)\n",
    "    similarity_score = float(cos_sim(embeds[0], embeds[1]))\n",
    "    return similarity_score\n",
    "\n",
    "\n",
    "\n",
    "def get_suitable_image(image_ids, query, query_emb, img_threshold=0.4):\n",
    "    text_to_image_ids = return_images_context(image_ids)\n",
    "    for i in text_to_image_ids:\n",
    "        print(text_to_image_ids[i])\n",
    "    # new_text_to_image_ids = dict()\n",
    "    images_context_values = list(text_to_image_ids.keys())\n",
    "\n",
    "    co = cohere.Client(api_key=COHERE_API_KEY)\n",
    "\n",
    "    model=\"embed-english-v3.0\"\n",
    "    input_type=\"search_query\"\n",
    "\n",
    "    # for i in images_context_values:\n",
    "    #     # print(i)\n",
    "    #     image_emb = co.embed(texts=[i],\n",
    "    #                 model=model,\n",
    "    #                 input_type=input_type)\n",
    "    #     val = float(cos_sim(query_emb.embeddings, image_emb.embeddings)[0][0])\n",
    "    #     if val >= img_threshold:\n",
    "    #         new_text_to_image_ids[i] = text_to_image_ids[i]\n",
    "            # print(i)\n",
    "            # print(val)\n",
    "            # print(new_text_to_image_ids[i])\n",
    "            # print(\"\\n\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Given a dictionary: {text_to_image_ids} and string: {query}, choose the key of the dictionary that is almost as close as possible to the string and return the value of the key in the dictionary.\n",
    "        Note: Check for similarity between the provided string and keys of the dictionary and only return the value of the key that is similar to the string.        \n",
    "        Choose the key of dictionary that is highly similar to the string provided so that I can get the value of the key and display that image in the UI.\n",
    "        Return only the value of the key choosen. I do not need anything else.\n",
    "    \"\"\"\n",
    "    time.sleep(1)\n",
    "    co = cohere.Client(COHERE_API_KEY)\n",
    "    response = co.chat(\n",
    "        message=prompt,\n",
    "        model=\"command-r\",\n",
    "        temperature=0\n",
    "    )\n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"answer from llm is: {response.text}\")\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "    \n",
    "    max_image_context = None\n",
    "    for key, value in text_to_image_ids.items():\n",
    "        if value == str(response.text):\n",
    "            max_image_context = key\n",
    "\n",
    "    print(f\"max_image content is: \\n{max_image_context}\")\n",
    "\n",
    "    if max_image_context is None:\n",
    "        return None, None\n",
    "\n",
    "    \n",
    "    \n",
    "    # image_emb = co.embed(texts=[max_image_context],\n",
    "    #             model=model,\n",
    "    #             input_type=input_type)\n",
    "    # val = float(cos_sim(query_emb.embeddings, image_emb.embeddings)[0][0])\n",
    "    val = float(get_similarity_together([query, max_image_context]))\n",
    "\n",
    "    print(f\"Image similarity value is {val}\")\n",
    "    if val >= img_threshold:\n",
    "        print(\"hi there\")\n",
    "        return str(response.text), max_image_context\n",
    "\n",
    "    else:\n",
    "        return None, None\n",
    "        \n",
    "    \n",
    "\n",
    "    # print(f\"\\n\\n{max_image_context}\")\n",
    "\n",
    "    # max_image_context = max(text_to_scores, key=text_to_scores.get)\n",
    "    # image_id = text_to_image_ids[max_image_context]\n",
    "\n",
    "    # for i in text_to_image_ids:\n",
    "    #     print(i)\n",
    "    #     print(text_to_image_ids[i])\n",
    "    #     print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_retriever(query: str) -> list[Document]:\n",
    "    \"\"\"RRF retriever\n",
    "\n",
    "    Args:\n",
    "        query (str): Query string\n",
    "\n",
    "    Returns:\n",
    "        list[Document]: retrieved documents\n",
    "    \"\"\"\n",
    "\n",
    "    # Retriever\n",
    "    embedding = CohereEmbeddings(model = \"embed-english-v3.0\")\n",
    "    \n",
    "    qdrant_client = QdrantClient(\n",
    "        QDRANT_URL,\n",
    "        prefer_grpc=True,\n",
    "        api_key=QDRANT_API_KEY,\n",
    "    )\n",
    "    print(qdrant_client)\n",
    "\n",
    "    qdrant = Qdrant(\n",
    "        client=qdrant_client,\n",
    "        collection_name=QDRANT_COLLECTION_NAME,\n",
    "        embeddings=embedding,\n",
    "    )\n",
    "\n",
    "    retriever = qdrant.as_retriever(\n",
    "        search_kwargs={'k': TOP_K},\n",
    "        metadata={}\n",
    "    )\n",
    "\n",
    "    # invoke\n",
    "    result = retriever.invoke(query)\n",
    "    print(result)\n",
    "\n",
    "    image_ids = []\n",
    "    from itertools import chain\n",
    "    for document in result:\n",
    "        image_ids.append(document.metadata['image_ids'])\n",
    "    image_ids = list(chain.from_iterable([item] if isinstance(item, str) else item for item in image_ids if item is not None))\n",
    "\n",
    "    print(image_ids)\n",
    "\n",
    "    return result, image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(query, threshold=0.3):\n",
    "    # chat_history = get_latest_data(USER_ID, SESSION_ID)\n",
    "    \n",
    "    # cache_response, image_ids_from_cache = semantic_cache.query_cache(query)\n",
    "    # if cache_response is not None:\n",
    "    #     return cache_response, image_ids_from_cache\n",
    "    \n",
    "    # context, image_ids = rrf_retriever(query)\n",
    "    context, image_ids = normal_retriever(query)\n",
    "    print(context)\n",
    "    context_list = list()\n",
    "    image_ids = list(set(image_ids))\n",
    "\n",
    "    for i in context:\n",
    "        context_list.append(i.page_content)\n",
    "\n",
    "    co = cohere.Client(api_key=COHERE_API_KEY)\n",
    "\n",
    "    model=\"embed-english-v3.0\"\n",
    "    input_type=\"search_query\"\n",
    "\n",
    "    query_emb = co.embed(texts=[f\"{query}\"],\n",
    "                model=model,\n",
    "                input_type=input_type)\n",
    "    \n",
    "    print(query_emb.embeddings)\n",
    "    \n",
    "    chat_history = None\n",
    "    image_id, max_image_content = None, None\n",
    "    counter = None\n",
    "\n",
    "    # Use ThreadPoolExecutor to run functions in parallel\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        # future_chat_history = executor.submit(get_latest_data, USER_ID, SESSION_ID)\n",
    "        future_image_id = executor.submit(get_suitable_image, image_ids, query, query_emb)\n",
    "        future_counter = executor.submit(check_probing_conditions, context_list, query_emb, threshold)\n",
    "        \n",
    "        # chat_history = future_chat_history.result()\n",
    "        image_id, max_image_content = future_image_id.result()\n",
    "        counter = future_counter.result()\n",
    "\n",
    "    prompt = None\n",
    "    flag_probe = False\n",
    "    chat_history = []\n",
    "\n",
    "    if (MAX_DOCS_FOR_CONTEXT - counter) <= 5:\n",
    "        prompt = f\"\"\"\n",
    "                You are a chatbot built for helping users understand car's owner manuals, try and ask probing questions related to that alone.\n",
    "                Create several question based on question:{query}, context: {context} and chat history of the user: {chat_history}.\n",
    "                As similarity between query and context is low, try to ask several probing questions.\n",
    "                Ask several followup questions to get further clarity.\n",
    "                Answer in a polite tone, and convey to the user that you need more clarity to answer the question.\n",
    "                Then display the probing questions as bulletin points.\n",
    "                Do not use technical words, give easy to understand responses.\n",
    "                If the question asked is a generic question or causal question answer them without using the context.\n",
    "                If the question is a general question, try to interact with the user in a polite way.\n",
    "            \"\"\"\n",
    "        flag_probe = True\n",
    "    else:\n",
    "        if image_id is None:\n",
    "            prompt = f\"\"\"\n",
    "                    You are a chatbot built for helping users understand car's owner manuals.\n",
    "                    Answer the question:{query} only based on the context: {context} and the chat history of the user: {chat_history} provided.\n",
    "                    Try to answer in bulletin points.\n",
    "                    Do not mention anything about images or figures.\n",
    "                    Do not use technical words, give easy to understand responses.\n",
    "                    Do not divulge any other details other than query or context.\n",
    "                    If the question asked is a generic question or causal question answer them without using the context.\n",
    "                    If the question is a general question, try to interact with the user in a polite way.\n",
    "                \"\"\"\n",
    "        else:\n",
    "            prompt = f\"\"\"\n",
    "                    You are a chatbot built for helping users understand car's owner manuals.\n",
    "                    Answer the question:{query} only based on the context: {context}, the chat history of the user: {chat_history} and this image summary: {max_image_content} provided.\n",
    "                    Try to answer in bulletin points.\n",
    "                    Do not use technical words, give easy to understand responses.\n",
    "                    Do not divulge any other details other than query or context.\n",
    "                    If the question asked is a generic question or causal question answer them without using the context.\n",
    "                    If the question is a general question, try to interact with the user in a polite way.\n",
    "                \"\"\"\n",
    "            \n",
    "\n",
    "    co = cohere.Client(COHERE_API_KEY)\n",
    "    response = co.chat(\n",
    "        message=prompt,\n",
    "        model=\"command-r\",\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    # semantic_cache.insert_into_cache(query, query_emb, response.text, image_id)\n",
    "\n",
    "    if flag_probe:\n",
    "        return response.text, None\n",
    "    else:\n",
    "        return response.text, image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# response, image_file_path = get_response(\"hyundai exter warranty\")\n",
    "\n",
    "# if image_file_path:\n",
    "#     plt_img_base64(get_file_details(image_file_path)['encoded_val'])\n",
    "# else:\n",
    "#     print(\"No image id detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<qdrant_client.qdrant_client.QdrantClient object at 0x000001CFB3AB10C0>\n",
      "<langchain_community.vectorstores.qdrant.Qdrant object at 0x000001CFAFDFD360>\n",
      "tags=['Qdrant', 'CohereEmbeddings'] metadata={} vectorstore=<langchain_community.vectorstores.qdrant.Qdrant object at 0x000001CFAFDFD360> search_kwargs={'k': 10}\n"
     ]
    }
   ],
   "source": [
    "# Retriever\n",
    "embedding = CohereEmbeddings(model = \"embed-english-v3.0\")\n",
    "\n",
    "qdrant_client = QdrantClient(\n",
    "    \"https://8803fa99-7551-4f88-84c3-e134c9bed5de.us-east4-0.gcp.cloud.qdrant.io:6333\",\n",
    "    prefer_grpc=True,\n",
    "    api_key=\"EFeN_UhdmAlDNYZHqJBUbZ88Nt7N0MkmvWLgM5Hs4ogNvExLMwNwdQ\",\n",
    ")\n",
    "print(qdrant_client)\n",
    "\n",
    "qdrant = Qdrant(\n",
    "    client=qdrant_client,\n",
    "    collection_name=\"manual\",\n",
    "    embeddings=embedding,\n",
    ")\n",
    "print(qdrant)\n",
    "retriever = qdrant.as_retriever(\n",
    "    search_kwargs={'k': TOP_K},\n",
    "    metadata={}\n",
    ")\n",
    "print(retriever)\n",
    "\n",
    "# invoke\n",
    "result = retriever.invoke(\"Warranty hyundai exter\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_emb = co.embed(texts=[\"hi there\"],\n",
    "#                 model=model,\n",
    "#                 input_type=input_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# co = cohere.Client(COHERE_API_KEY)\n",
    "# response = co.chat(\n",
    "#     message=\"Tell me about ms dhoni\",\n",
    "#     model=\"command-r\",\n",
    "#     temperature=0\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
