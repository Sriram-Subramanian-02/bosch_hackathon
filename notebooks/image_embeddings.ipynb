{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image Embeddings\n",
        "\n",
        "This notebook creates extracts all the images from owners manual and creates image embeddings \n",
        "using clip model in roboflow, which are stored in a QDrant Collection. Metadata containg image_id will be stored aswell, which are used for image based search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvh14P_k2oQa",
        "outputId": "fc780b35-e2ab-4984-f247-918eefa9bae8"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-cpu\n",
        "!pip install sentence_transformers\n",
        "!pip install pymupdf\n",
        "!pip install qdrant-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bm_rZlfQ2j-J"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/shimer/College/BOSCH_HACKATHON/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import base64\n",
        "import requests\n",
        "\n",
        "from transformers import CLIPProcessor, CLIPModel, CLIPTokenizer\n",
        "from sentence_transformers.util import cos_sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8lWX7j22j-L"
      },
      "outputs": [],
      "source": [
        "def get_model_info(model_ID, device):\n",
        "\tmodel = CLIPModel.from_pretrained(model_ID).to(device)\n",
        "\tprocessor = CLIPProcessor.from_pretrained(model_ID)\n",
        "\ttokenizer = CLIPTokenizer.from_pretrained(model_ID)\n",
        "\treturn model, processor, tokenizer\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_ID = \"openai/clip-vit-base-patch32\"\n",
        "model, processor, tokenizer = get_model_info(model_ID, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_model(file_path = \"F:\\\\psg\\\\bosch_hackathon\\\\models\"):\n",
        "    from transformers import Trainer\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "    trainer.save_model(f\"{file_path}\\\\clip_model\")\n",
        "    tokenizer.save_pretrained(f\"{file_path}\\\\clip_model\")\n",
        "\n",
        "\n",
        "def load_model(file_path = \"F:\\\\psg\\\\bosch_hackathon\\\\models\"):\n",
        "    model = CLIPModel.from_pretrained(f\"{file_path}\\\\clip_model\")\n",
        "    processor = CLIPProcessor.from_pretrained(model_ID)\n",
        "    tokenizer = CLIPTokenizer.from_pretrained(f\"{file_path}\\\\clip_model\")\n",
        "\n",
        "    return model, processor, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsDvSAaI2j-N"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def get_single_image_embedding_clip(image_path):\n",
        "    my_image = Image.open(image_path)\n",
        "\n",
        "    image = processor(\n",
        "        text=None,\n",
        "        images=my_image,\n",
        "        return_tensors=\"pt\"\n",
        "    )[\"pixel_values\"].to(device)\n",
        "\n",
        "    # Get the image features\n",
        "    embedding = model.get_image_features(image)\n",
        "    embedding_as_np = embedding.cpu().detach().numpy()\n",
        "\n",
        "    return embedding_as_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def encode_image(image_path):\n",
        "    ''' Getting the base64 string '''\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode('utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_single_image_embedding_roboflow(image_path):\n",
        "    encoded_val = encode_image(image_path)\n",
        "    infer_clip_payload = {\n",
        "        \"image\": {\n",
        "            \"type\": \"base64\",\n",
        "            \"value\": f\"{encoded_val}\",\n",
        "        },\n",
        "    }\n",
        "\n",
        "    base_url = \"https://infer.roboflow.com\"\n",
        "    api_key = \"pUmnI6Vv3mdDdmDiEtqz\"\n",
        "\n",
        "    res = requests.post(\n",
        "        f\"{base_url}/clip/embed_image?api_key={api_key}\",\n",
        "        json=infer_clip_payload,\n",
        "    )\n",
        "\n",
        "    embeddings = res.json()\n",
        "\n",
        "    if \"embeddings\" in embeddings:\n",
        "        return embeddings['embeddings'][0]\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwSu0ILqFN1U"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import pymupdf\n",
        "import fitz\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4QbyctGIIx5"
      },
      "outputs": [],
      "source": [
        "# Sriram's QDrant\n",
        "qdrant_client = QdrantClient(\n",
        "    \"https://35ebdc7d-ec99-4ebd-896c-ff5705cf369b.us-east4-0.gcp.cloud.qdrant.io:6333\",\n",
        "    prefer_grpc=True,\n",
        "    api_key=\"9dKJsKOYwT0vGlWPrZXBSIlbUzvRdJ1XkM0_floo8FmYCOHX_Y0y-Q\",\n",
        ")\n",
        "\n",
        "QDRANT_URL = \"https://35ebdc7d-ec99-4ebd-896c-ff5705cf369b.us-east4-0.gcp.cloud.qdrant.io:6333\"\n",
        "QDRANT_API_KEY = \"9dKJsKOYwT0vGlWPrZXBSIlbUzvRdJ1XkM0_floo8FmYCOHX_Y0y-Q\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-pQHCoOIEO7",
        "outputId": "675476d2-dde8-4cfe-a488-e52b161640d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-51-e40245b700b6>:3: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
            "  qdrant_client.recreate_collection(\n"
          ]
        }
      ],
      "source": [
        "def create_QDrant_collection():\n",
        "\t\tembeddings = model\n",
        "\t\tqdrant_client.recreate_collection(\n",
        "\t\tcollection_name=\"owners_manual_images\",\n",
        "\t\tvectors_config = models.VectorParams(size=512, distance=models.Distance.COSINE),\n",
        "\t)\n",
        "\n",
        "create_QDrant_collection()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dEK4B7N2j-O"
      },
      "outputs": [],
      "source": [
        "def extract_data(file_path, source_file, car_name, start_idx):\n",
        "    doc = pymupdf.open(file_path)\n",
        "    pdf_file = fitz.open(file_path)\n",
        "    data = list()\n",
        "\n",
        "    records_to_upload = []\n",
        "    for i, page in enumerate(doc):\n",
        "        print(f\"Page no is {i}\")\n",
        "\n",
        "        image_list = page.get_images(full=True)\n",
        "\n",
        "        if image_list:\n",
        "            print(f\"[+] Found a total of {len(image_list)} images in page {i}\")\n",
        "        else:\n",
        "            print(\"[!] No images found on page\", i)\n",
        "\n",
        "\n",
        "        for image_index, img in enumerate(page.get_images(full=True), start=1):\n",
        "            xref = img[0]\n",
        "            base_image = pdf_file.extract_image(xref)\n",
        "            image_bytes = base_image[\"image\"]\n",
        "            image_ext = base_image[\"ext\"]\n",
        "            image = Image.open(io.BytesIO(image_bytes))\n",
        "            image_id = f\"image_{source_file}_{i}_{image_index}.{image_ext}\"\n",
        "            img_path = f\"/content/Manual_Images/{source_file}/{image_id}\"\n",
        "            image.save(open(img_path, \"wb\"))\n",
        "\n",
        "            image_embeddings = get_single_image_embedding_roboflow(img_path)\n",
        "\n",
        "            chunk_metadata = {\n",
        "                \"image_id\": image_id,\n",
        "                \"car_name\": car_name,\n",
        "            }\n",
        "            payload = {\"metadata\": chunk_metadata}\n",
        "\n",
        "            record = models.PointStruct(\n",
        "                id=start_idx + image_index,\n",
        "                vector=image_embeddings[0].tolist(),\n",
        "                payload=payload\n",
        "            )\n",
        "            records_to_upload.append(record)\n",
        "        start_idx += len(image_list)\n",
        "\n",
        "    qdrant_client.upload_points(\n",
        "        collection_name=\"owners_manual_images\",\n",
        "        points=records_to_upload\n",
        "    )\n",
        "    return start_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXudhtNCE5sk"
      },
      "outputs": [],
      "source": [
        "start_idx = extract_data(\"/content/hyundai_exter.pdf\", \"hyundai_exter\", \"Hyundai Exter\", 0)\n",
        "start_idx"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
